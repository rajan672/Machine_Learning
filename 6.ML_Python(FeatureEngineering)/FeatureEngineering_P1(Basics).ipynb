{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "386ea650",
   "metadata": {},
   "source": [
    "# Feature Engineering for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c80893",
   "metadata": {},
   "source": [
    "### 1.What is Feature Engineering?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d37a76",
   "metadata": {},
   "source": [
    "#### Feature engineering is the pre-processing step of machine learning, which extracts features from raw data. \n",
    "It helps to represent an underlying problem to predictive models in a better way, which as a result, improve the accuracy of the model for unseen data. The predictive model contains predictor variables and an outcome variable, and while the feature engineering process selects the most useful predictor variables for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfd2f56",
   "metadata": {},
   "source": [
    "## 2.Feature Engineering Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7facc1",
   "metadata": {},
   "source": [
    "### Some of the popular feature engineering techniques include:\n",
    "\n",
    "1. Imputation :-\n",
    "Feature engineering deals with inappropriate data, missing values, human interruption, general errors, insufficient data sources, etc. Missing values within the dataset highly affect the performance of the algorithm, and to deal with them \"Imputation\" technique is used. Imputation is responsible for handling irregularities within the dataset.\n",
    "\n",
    "2. Handling Outliers :-\n",
    "Outliers are the deviated values or data points that are observed too away from other data points in such a way that they badly affect the performance of the model. Outliers can be handled with this feature engineering technique. This technique first identifies the outliers and then remove them out.\n",
    "Standard deviation can be used to identify the outliers. For example, each value within a space has a definite to an average distance, but if a value is greater distant than a certain value, it can be considered as an outlier. Z-score can also be used to detect outliers.\n",
    "\n",
    "3. Log transform :-\n",
    "Logarithm transformation or log transform is one of the commonly used mathematical techniques in machine learning. Log transform helps in handling the skewed data, and it makes the distribution more approximate to normal after transformation. It also reduces the effects of outliers on the data, as because of the normalization of magnitude differences, a model becomes much robust.\n",
    "Note: Log transformation is only applicable for the positive values; else, it will give an error. To avoid this, we can add 1 to the data before transformation, which ensures transformation to be positive.\n",
    "    \n",
    "4. Binning :-\n",
    "In machine learning, overfitting is one of the main issues that degrade the performance of the model and which occurs due to a greater number of parameters and noisy data. However, one of the popular techniques of feature engineering, \"binning\", can be used to normalize the noisy data. This process involves segmenting different features into bins.\n",
    "\n",
    "5. Feature Split :-\n",
    "As the name suggests, feature split is the process of splitting features intimately into two or more parts and performing to make new features. This technique helps the algorithms to better understand and learn the patterns in the dataset.\n",
    "The feature splitting process enables the new features to be clustered and binned, which results in extracting useful information and improving the performance of the data models.\n",
    "\n",
    "6. One hot encoding :-\n",
    "One hot encoding is the popular encoding technique in machine learning. It is a technique that converts the categorical data in a form so that they can be easily understood by machine learning algorithms and hence can make a good prediction. It enables group the of categorical data without losing any information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac48f48b",
   "metadata": {},
   "source": [
    "# 3.Types of Variables "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ef49ff",
   "metadata": {},
   "source": [
    "1.Numerical Variable :- \n",
    "(1) Discrete Numerical Variable:- Integer variable \n",
    "(2) Continuous Numerical Variable:- Float variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbf20a0",
   "metadata": {},
   "source": [
    "2.Categorical Variable :-Character variables   (1) Ordinal Categorical Variable :- ordered Variable i.e. Sun,Mon,Tue (2) Nominal Categorical Variable :- not in order like car , bus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0798b4b9",
   "metadata": {},
   "source": [
    "3.Dates & Time :- deals with date and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44988dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
